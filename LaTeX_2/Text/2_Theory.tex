\section{Theory}    \label{sec:02:theory}

\subsection{Memory Units}
Every digital memory unit is built up hierarchically by several word cells. The size of each word may vary from system to system (8-bit, 16-bit, 32-bit, etc.), but no matter the architecture, the smallest unit of memory, the bitcell, is present. The total available bits in the memory is the product of the number of bits per word times number of words in the unit. Every bit is addressable by a unique address that points to a single word in the unit. When reading or writing a word, the whole word is accessed, and should individual bits be of interest, then those must be parsed from the word.

The bitcells within each word are designed differently depending on the level of transparency required. There are several options for storing a single digital value, such as latches and flip-flops. Latches are transparent in the sense that once enabled, the output will follow the input immediately (with some negligible delay). Flip-flops on the other hand are not transparent: The output must always be overwritten by a rising or falling clock edge, thus delaying the output compared to the input.

\subsection{Power Reduction}
Total power consumption of a system is usually calculated as the sum of the static power consumption and the dynamic power consumption. The static power consumption is always present, even when the system is idle, meaning no inputs or outputs are changing. The dynamic power consumption is the extra power required to change the states of the system.

\begin{equation}
    P_{total} = P_{static} + P_{dynamic}
    \label{eq:02:total_power}
\end{equation}

Static power consumption is calculated by the average number of transistors that are in the active region, and how much each transistor leaks. The dynamic power consumption depends on many factors, but it can be reduced by lowering any of the system factors it is proportional to, see \autoref{eq:02:dynamic_power} \cite{forelesningslidesPower}.

\begin{equation}
    P_{dynamic} \propto f_{clk} \cdot C_{load} \cdot V_{DD}^2
    \label{eq:02:dynamic_power}
\end{equation}

In recent years, with clock frequencies stagnating, contrary to Moore's law, and supply voltages being minimized, it is the static power consumption that ends up contributing the most to the overall power consumption. In order to reduce power consumption in a 'System on a Chip' (SoC) there are many factors to consider, but some very common ones are to: 
\begin{itemize}
    \item Reduce the number of transistors in the system as a whole.
    \item Reduce the current through each transistor when in the active region, which can be estimated with equation \ref{eq:02:drain_current} \cite{analog2011}. 
    \item Reduce the supply voltage
    \item Reduce the switching frequency / clock frequency.
    \item Reduce the width-to-length ratio.
    \item Minimize the difference between voltage supply and threshold voltage of the transistors ($V_{eff}$).
\end{itemize}

To achieve the last bullet point, one may choose to either lower the voltage supply directly or increase the threshold voltage by tuning the bulk voltage of each transistor. 

\begin{equation}
    I_D = \frac{\mu C_{ox}}{2} \frac{W}{L} (V_{GS} - V_T)^2 
    \label{eq:02:drain_current}
\end{equation}


\subsection{Process variation corners}
When producing SoC's, the transistors on the wafer are prone to be slightly different from each other depending on a number of factors. For instance, transistors made in proximity on the wafer are more likely to be similar to each other than transistors placed further apart. These process variations can make some transistors switch on/off faster than others in unforeseen ways. In order to sufficiently simulate a system, we divide the transistor variations into five different simulation "corners" according to how fast they are switching.

\begin{itemize}
    \item \makebox[1cm]{FF \hfill} \makebox[2.5cm]{\textit{Fast-Fast} \hfill} Fast operating NMOS and Fast operating PMOS 
    \item \makebox[1cm]{SS \hfill} \makebox[2.5cm]{\textit{Slow-Slow} \hfill} Slow operating NMOS and Slow operating PMOS 
    \item \makebox[1cm]{FS \hfill} \makebox[2.5cm]{\textit{Fast-Slow} \hfill} Fast operating NMOS and Slow operating PMOS 
    \item \makebox[1cm]{SF \hfill} \makebox[2.5cm]{\textit{Slow-Fast} \hfill} Slow operating NMOS and Fast operating PMOS 
    \item \makebox[1cm]{TT \hfill} \makebox[2.5cm]{\textit{Typical-Typical} \hfill} Typical operating NMOS and Typical operating PMOS 
\end{itemize}

The advantages of fast-operating transistors include faster switching times and lower threshold voltages, meaning that they can operate on a lower voltage supply. However they have higher power consumptions due to the higher leakage current and faster switching. The leakage current is a result of the shorter channel lengths meaning less capacitance between the channels. The lowered threshold voltage $V_T$ will also provide higher leakage current. When $V_T$ is lowered, it means that even a small voltage at the gate can cause the transistor to start conducting, making it more susceptible to noise-induced leakage. Additionally, sub-threshold leakage occurs when the gate voltage is below $V_T$, but still close enough to allow small currents to flow through the channel. In contrast to fast transistors, slow transistors have a higher $V_T$ and thus lower power consumption, which makes them ideal for low energy implementations. However, these simulation corners are not chosen, they are simulated to make sure the system can operate with transistors that are slightly different to what was intended. The ideal design would be the \textit{TT} corner, but the system has to be designed to work within all of the corners.
